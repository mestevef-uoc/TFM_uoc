{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPr73G26frmrE+K3FxPlKJk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["UNSW-NB15 dataset\n","\n","Explanation of Key Features:\n","\n","\n","\n","* **id**: A unique identifier for each record.\n","*  **dur** (duration): Duration of the connection in seconds, indicating how long a connection lasts.\n","*  **proto** (protocol): The protocol used for the connection (e.g., TCP, UDP, ICMP).\n","*  **service**: Type of service involved (e.g., HTTP, FTP, SMTP).\n","*  **state**: State of the connection (e.g., FIN, CON, INT).\n","*  **spkts** (source packets): Number of packets sent by the source.\n","*  **dpkts** (destination packets): Number of packets received by the destination.\n","*  **sbytes** (source bytes): Number of bytes sent by the source.\n","* **dbytes** (destination bytes): Number of bytes received by the destination.\n","*  **rate**: Traffic flow rate.\n","* **sttl** (source time-to-live): The TTL value set by the source; used in analyzing packet lifetimes.\n","*  **dttl** (destination time-to-live): The TTL value set by the destination.\n","*  **sload** (source load): Load on the source during the connection.\n","*  **dload** (destination load): Load on the destination during the connection.\n","* **sloss** (source loss): Number of packets lost by the source.\n","*  **dloss** (destination loss): Number of packets lost by the destination.\n","* **sinpkt** (source inter-packet arrival time): Time between packets sent by the source.\n","* **dinpkt** (destination inter-packet arrival time): Time between packets received by the destination.\n","* **sjit** (source jitter): Jitter in the packet flow from the source.\n","* **djit** (destination jitter): Jitter in the packet flow to the destination.\n","* **swin** (source window size): The size of the source's TCP window.\n","* **stcpb** (source TCP base sequence number): TCP sequence number from the source.\n","* **dtcpb** (destination TCP base sequence number): TCP sequence number from the destination.\n","* **dwin** (destination window size): The size of the destination's TCP window.\n","* **tcprtt** (TCP round-trip time): Round-trip time for TCP packets.\n","* **synack**: Time between SYN and ACK packets.\n","* **ackdat**: Time between ACK packets.\n","* **smean** (source mean): Mean of the source's data.\n","* **dmean** (destination mean): Mean of the destination's data.\n","* **trans_depth**: The depth of the connection, indicating levels of HTTP transactions.\n","* **response_body_len**: Length of the response body.\n","* **ct_srv_src**: Count of connections to the same service from the same source.\n","* **ct_state_ttl**: Count of connections with the same state and TTL.\n","* **ct_dst_ltm**: Count of connections to the same destination over time.\n","* **ct_src_dport_ltm**: Count of connections from the same source to a specific destination port over time.\n","* **ct_dst_sport_ltm**: Count of connections to the same destination from a specific source port over time.\n","* **ct_dst_src_ltm**: Count of connections between the same source and destination.\n","* **is_ftp_login**: Binary indicator of whether an FTP login attempt was made.\n","* **ct_ftp_cmd**: Number of FTP commands in the connection.\n","* **ct_flw_http_mthd**: Number of HTTP methods used in the connection.\n","* **ct_src_ltm**: Count of connections from the same source over time.\n","* **ct_srv_dst**: Count of connections to the same service at the destination.\n","* **is_sm_ips_ports**: Binary indicator if the source and destination IPs and ports are the same.\n","* **attack_cat**: The category of the attack (e.g., DoS, Probe, Normal).\n","* **label**: Binary classification label (0 for normal traffic, 1 for malicious traffic)."],"metadata":{"id":"TgzB4MF9OTKG"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vk52F7pnG1cP","executionInfo":{"status":"ok","timestamp":1730748786666,"user_tz":-60,"elapsed":32610,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}},"outputId":"26b2b6f7-45eb-4c32-f491-f94430b8a3b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Paths to the CSV files in the 'datasets' folder\n","training_set_path = '/content/drive/My Drive/datasets/UNSW_NB15_training-set.csv'\n","testing_set_path = '/content/drive/My Drive/datasets/UNSW_NB15_testing-set.csv'\n","\n"],"metadata":{"id":"Sqm34R4gOXOR","executionInfo":{"status":"ok","timestamp":1730750735141,"user_tz":-60,"elapsed":274,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the training, testing, and feature CSV files\n","training_df = pd.read_csv(training_set_path)\n","testing_df = pd.read_csv(testing_set_path)\n","\n","\n","# Display the first few rows of each dataframe to ensure they loaded correctly\n","print(\"Training Set:\")\n","print(training_df.head())\n","\n","print(\"\\nTesting Set:\")\n","print(testing_df.head())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4N4FuxKcOXym","executionInfo":{"status":"ok","timestamp":1730750743801,"user_tz":-60,"elapsed":1655,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}},"outputId":"19e92593-3571-44b4-af71-6bd1052b9c74"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Set:\n","   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n","0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n","1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n","2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n","3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n","4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n","\n","   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n","0  ...                 1               1             0           0   \n","1  ...                 1               2             0           0   \n","2  ...                 1               3             0           0   \n","3  ...                 1               3             1           1   \n","4  ...                 1              40             0           0   \n","\n","   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n","0                 0           1           1                0      Normal   \n","1                 0           1           6                0      Normal   \n","2                 0           2           6                0      Normal   \n","3                 0           2           1                0      Normal   \n","4                 0           2          39                0      Normal   \n","\n","   label  \n","0      0  \n","1      0  \n","2      0  \n","3      0  \n","4      0  \n","\n","[5 rows x 45 columns]\n","\n","Testing Set:\n","   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n","0   1  0.000011   udp       -   INT      2      0     496       0   \n","1   2  0.000008   udp       -   INT      2      0    1762       0   \n","2   3  0.000005   udp       -   INT      2      0    1068       0   \n","3   4  0.000006   udp       -   INT      2      0     900       0   \n","4   5  0.000010   udp       -   INT      2      0    2126       0   \n","\n","          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n","0   90909.0902  ...                 1               2             0   \n","1  125000.0003  ...                 1               2             0   \n","2  200000.0051  ...                 1               3             0   \n","3  166666.6608  ...                 1               3             0   \n","4  100000.0025  ...                 1               3             0   \n","\n","   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n","0           0                 0           1           2                0   \n","1           0                 0           1           2                0   \n","2           0                 0           1           3                0   \n","3           0                 0           2           3                0   \n","4           0                 0           2           3                0   \n","\n","   attack_cat  label  \n","0      Normal      0  \n","1      Normal      0  \n","2      Normal      0  \n","3      Normal      0  \n","4      Normal      0  \n","\n","[5 rows x 45 columns]\n"]}]},{"cell_type":"markdown","source":["This dataset includes both numerical and categorical features that describe network connections.\n","The target columns, attack_cat and label, are used to differentiate between normal and anomalous/malicious traffic.\n","The label column is particularly important for binary classification tasks, indicating whether the traffic is normal (0) or an attack (1).\n","The attack_cat column provides more detailed information about the type of attack, which can be used for multi-class classification."],"metadata":{"id":"CurdtCs9er1K"}},{"cell_type":"code","source":["#Aqui calculem la correlation matrix pero exloent els valors numerics.\n","\n","# Select only numeric columns and drop the 'id' column\n","numeric_df = training_df.select_dtypes(include=['number']).drop(columns=['id'])\n","\n","# Calculate the correlation matrix\n","correlation_matrix = numeric_df.corr()\n","\n","# Extract correlation scores for the target variable (assuming the target column is 'label')\n","target_correlations = correlation_matrix['label'].sort_values(ascending=False)\n","\n","# Create a DataFrame to display the results as a table\n","correlation_table = pd.DataFrame({\n","    'Feature': target_correlations.index,\n","    'Correlation Score': target_correlations.values\n","})\n","\n","# Exclude the target variable itself from the table\n","correlation_table = correlation_table[correlation_table['Feature'] != 'label']\n","\n","# Add a ranking column\n","correlation_table['Rank'] = range(1, len(correlation_table) + 1)\n","\n","# Display the correlation table\n","print(correlation_table)\n","\n","# Optionally, display the top 10 features\n","print(\"\\nTop 10 Features by Correlation Score:\")\n","print(correlation_table.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8waEbji5ojD0","executionInfo":{"status":"ok","timestamp":1730749782956,"user_tz":-60,"elapsed":1570,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}},"outputId":"5e5f5b0b-8d64-426d-afd8-a0b98e5a35ae"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["              Feature  Correlation Score  Rank\n","1                sttl           0.692741     1\n","2        ct_state_ttl           0.577704     2\n","3    ct_dst_sport_ltm           0.357213     3\n","4                rate           0.337979     4\n","5    ct_src_dport_ltm           0.305579     5\n","6      ct_dst_src_ltm           0.303855     6\n","7          ct_src_ltm           0.238225     7\n","8          ct_dst_ltm           0.229887     8\n","9          ct_srv_src           0.229044     9\n","10         ct_srv_dst           0.228046    10\n","11              sload           0.182870    11\n","12             ackdat           0.097364    12\n","13               dttl           0.095049    13\n","14             tcprtt           0.081584    14\n","15             synack           0.058299    15\n","16                dur           0.036175    16\n","17             sbytes           0.018576    17\n","18   ct_flw_http_mthd           0.015800    18\n","19        trans_depth           0.010801    19\n","20              sloss          -0.000640    20\n","21               sjit          -0.007069    21\n","22              smean          -0.010798    22\n","23         ct_ftp_cmd          -0.011055    23\n","24       is_ftp_login          -0.011055    24\n","25  response_body_len          -0.021361    25\n","26             dinpkt          -0.022887    26\n","27              spkts          -0.052178    27\n","28               djit          -0.060870    28\n","29             dbytes          -0.076871    29\n","30              dloss          -0.094685    30\n","31              dpkts          -0.118591    31\n","32             sinpkt          -0.176110    32\n","33    is_sm_ips_ports          -0.184679    33\n","34              dtcpb          -0.250340    34\n","35              stcpb          -0.255006    35\n","36               dwin          -0.319626    36\n","37               swin          -0.333633    37\n","38              dmean          -0.341806    38\n","39              dload          -0.393739    39\n","\n","Top 10 Features by Correlation Score:\n","             Feature  Correlation Score  Rank\n","1               sttl           0.692741     1\n","2       ct_state_ttl           0.577704     2\n","3   ct_dst_sport_ltm           0.357213     3\n","4               rate           0.337979     4\n","5   ct_src_dport_ltm           0.305579     5\n","6     ct_dst_src_ltm           0.303855     6\n","7         ct_src_ltm           0.238225     7\n","8         ct_dst_ltm           0.229887     8\n","9         ct_srv_src           0.229044     9\n","10        ct_srv_dst           0.228046    10\n"]}]},{"cell_type":"markdown","source":["Step-by-Step Guide to Implement the Analysis:\n","Preprocess the Data:\n","\n","Select the top n features according to their correlation scores.\n","Encode categorical features (if any) and scale numerical features for consistency.\n"],"metadata":{"id":"uVmLyFffs6XX"}},{"cell_type":"code","source":["\n","#Tornem a fer el mateix pero incloent els categoric values en el case del training set hi ha tres columnes\n","#amb categorical values - proto , state and attack_cat\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","\n","# Print original columns to ensure non-numeric columns are included\n","print(\"Original Columns:\", training_df.columns)\n","\n","# Replace non-numeric placeholders (e.g., '-') with NaN\n","training_df.replace('-', pd.NA, inplace=True)\n","\n","# Optionally, convert columns to numeric, coercing errors to NaN for better handling\n","training_df = training_df.apply(pd.to_numeric, errors='coerce')\n","\n","# Check for any remaining non-numeric values\n","print(\"Number of non-numeric values per column:\")\n","print(training_df.isna().sum())\n","\n","# Fill or drop NaNs as needed (example: fill with 0 or drop rows with NaNs)\n","# training_df.fillna(0, inplace=True)  # Option 1: Fill NaNs with 0\n","# training_df.dropna(inplace=True)     # Option 2: Drop rows with NaNs\n","\n","# Proceed with correlation analysis\n","\n","# Drop the 'id' column before calculating the correlation matrix\n","training_df_no_id = training_df.drop(columns=['id'])\n","\n","# Calculate the correlation matrix\n","correlation_matrix = training_df_no_id.corr()\n","\n","target_correlations = correlation_matrix['label'].sort_values(ascending=False)\n","\n","# Create a DataFrame for correlation results\n","correlation_table = pd.DataFrame({\n","    'Feature': target_correlations.index,\n","    'Correlation Score': target_correlations.values\n","})\n","\n","correlation_table = correlation_table[correlation_table['Feature'] != 'label']\n","correlation_table['Rank'] = range(1, len(correlation_table) + 1)\n","\n","# Display the correlation table\n","print(correlation_table.head(10))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgk7LL-5ywkn","executionInfo":{"status":"ok","timestamp":1730751097783,"user_tz":-60,"elapsed":1861,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}},"outputId":"da3bbd8f-df93-48e1-eba6-9cc79d0f521a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Columns: Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n","       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n","       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n","       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n","       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n","       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n","       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n","       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n","      dtype='object')\n","Number of non-numeric values per column:\n","id                        0\n","dur                       0\n","proto                     0\n","service              175341\n","state                     0\n","spkts                     0\n","dpkts                     0\n","sbytes                    0\n","dbytes                    0\n","rate                      0\n","sttl                      0\n","dttl                      0\n","sload                     0\n","dload                     0\n","sloss                     0\n","dloss                     0\n","sinpkt                    0\n","dinpkt                    0\n","sjit                      0\n","djit                      0\n","swin                      0\n","stcpb                     0\n","dtcpb                     0\n","dwin                      0\n","tcprtt                    0\n","synack                    0\n","ackdat                    0\n","smean                     0\n","dmean                     0\n","trans_depth               0\n","response_body_len         0\n","ct_srv_src                0\n","ct_state_ttl              0\n","ct_dst_ltm                0\n","ct_src_dport_ltm          0\n","ct_dst_sport_ltm          0\n","ct_dst_src_ltm            0\n","is_ftp_login              0\n","ct_ftp_cmd                0\n","ct_flw_http_mthd          0\n","ct_src_ltm                0\n","ct_srv_dst                0\n","is_sm_ips_ports           0\n","attack_cat                0\n","label                     0\n","dtype: int64\n","             Feature  Correlation Score  Rank\n","1               sttl           0.692741     1\n","2       ct_state_ttl           0.577704     2\n","3              state           0.497685     3\n","4   ct_dst_sport_ltm           0.357213     4\n","5               rate           0.337979     5\n","6   ct_src_dport_ltm           0.305579     6\n","7     ct_dst_src_ltm           0.303855     7\n","8         ct_src_ltm           0.238225     8\n","9         ct_dst_ltm           0.229887     9\n","10        ct_srv_src           0.229044    10\n"]}]},{"cell_type":"code","source":["# Define the top features based on your correlation matrix\n","top_features = ['sttl', 'ct_state_ttl', 'state', 'ct_dst_sport_ltm', 'rate',\n","                'ct_src_dport_ltm', 'ct_dst_src_ltm', 'ct_src_ltm', 'ct_dst_ltm', 'ct_srv_src']\n","\n","# Define the target variable\n","target = 'label'\n"],"metadata":{"id":"z_Tc0PKL_seq","executionInfo":{"status":"ok","timestamp":1730754508758,"user_tz":-60,"elapsed":253,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Apply Label Encoding safely with .loc to avoid SettingWithCopyWarning\n","for feature in categorical_features:\n","    if feature in X_train.columns:\n","        # Fit the encoder only on the training set\n","        label_encoder.fit(X_train[feature])\n","\n","        # Transform training and testing sets\n","        X_train.loc[:, feature] = label_encoder.transform(X_train[feature])\n","\n","        # Transform the test set with the same encoder; handle unseen labels\n","        X_test.loc[:, feature] = X_test[feature].apply(lambda x: label_encoder.transform([x])[0] if x in label_encoder.classes_ else -1)\n","\n","\n"],"metadata":{"id":"d_ezHDbp_w_V","executionInfo":{"status":"ok","timestamp":1730754512912,"user_tz":-60,"elapsed":495,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Initialize and fit the scaler on the training data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","\n","# Apply the same scaling to the testing data\n","X_test_scaled = scaler.transform(X_test)\n"],"metadata":{"id":"vwfY0anlBK7J","executionInfo":{"status":"ok","timestamp":1730754689390,"user_tz":-60,"elapsed":291,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","import xgboost as xgb\n","\n","# List of models to train and evaluate\n","models = {\n","    'Naive Bayes': GaussianNB(),\n","    'LDA': LDA(),\n","    'KNN': KNeighborsClassifier(),\n","    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'SVM': SVC(),\n","    'AdaBoost': AdaBoostClassifier(),\n","    'SGD': SGDClassifier(),\n","    'Logistic Regression': LogisticRegression()\n","}\n","\n","# Function to train and evaluate models\n","def evaluate_models(X_train, X_test, y_train, y_test):\n","    results = {}\n","\n","    for name, model in models.items():\n","        print(f\"Training {name}...\")\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate performance metrics\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, zero_division=1)\n","        recall = recall_score(y_test, y_pred, zero_division=1)\n","        f1 = f1_score(y_test, y_pred, zero_division=1)\n","\n","        # Store results\n","        results[name] = {\n","            'Accuracy': round(accuracy * 100, 2),\n","            'Precision': round(precision * 100, 2),\n","            'Recall': round(recall * 100, 2),\n","            'F1 Score': round(f1 * 100, 2)\n","        }\n","\n","    return pd.DataFrame.from_dict(results, orient='index')\n","\n","# Evaluate the models using the prepared data\n","results = evaluate_models(X_train_scaled, X_test_scaled, y_train, y_test)\n","print(\"\\nModel Performance with Top Features:\")\n","print(results)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB5wLKodBaii","executionInfo":{"status":"ok","timestamp":1730756082456,"user_tz":-60,"elapsed":1327805,"user":{"displayName":"Marta Esteve","userId":"14816831829261294634"}},"outputId":"e5a745d8-5cce-4ef1-ea9b-ddda77b1a291"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Naive Bayes...\n","Training LDA...\n","Training KNN...\n","Training XGBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:13:20] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training Decision Tree...\n","Training Random Forest...\n","Training SVM...\n","Training AdaBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training SGD...\n","Training Logistic Regression...\n","\n","Model Performance with Top Features:\n","                     Accuracy  Precision  Recall  F1 Score\n","Naive Bayes             58.39      90.33   27.36     41.99\n","LDA                     73.31      72.26   83.64     77.53\n","KNN                     68.77      71.20   72.66     71.93\n","XGBoost                 80.83      74.25   99.78     85.14\n","Decision Tree           84.02      79.61   95.41     86.80\n","Random Forest           84.35      78.47   98.65     87.41\n","SVM                     73.52      75.23   77.38     76.29\n","AdaBoost                80.15      74.45   97.35     84.37\n","SGD                     71.85      69.74   86.31     77.15\n","Logistic Regression     70.82      71.26   78.76     74.82\n"]}]}]}